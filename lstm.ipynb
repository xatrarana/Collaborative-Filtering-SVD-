{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"She sells sea shells by the sea shore\",\n",
    "    \"How much wood would a woodchuck chuck if a woodchuck could chuck wood\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and sequence preparation (replace with your tokenizer)\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "sequences = tokenizer.texts_to_sequences(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequences to input-output pairs\n",
    "input_sequences = []\n",
    "output_words = []\n",
    "for sequence in sequences:\n",
    "    for i in range(1, len(sequence)):\n",
    "        input_sequence = sequence[:i]\n",
    "        output_word = sequence[i]\n",
    "        input_sequences.append(input_sequence)\n",
    "        output_words.append(output_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences (optional step)\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=100))\n",
    "model.add(Dense(units=len(tokenizer.word_index) + 1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=[[ 0  0  0  0  0  0  0  0  0  0  0  1]\n [ 0  0  0  0  0  0  0  0  0  0  1  7]\n [ 0  0  0  0  0  0  0  0  0  1  7  8]\n [ 0  0  0  0  0  0  0  0  1  7  8  9]\n [ 0  0  0  0  0  0  0  1  7  8  9 10]\n [ 0  0  0  0  0  0  1  7  8  9 10 11]\n [ 0  0  0  0  0  1  7  8  9 10 11  1]\n [ 0  0  0  0  1  7  8  9 10 11  1 12]\n [ 0  0  0  0  0  0  0  0  0  0  0 14]\n [ 0  0  0  0  0  0  0  0  0  0 14 15]\n [ 0  0  0  0  0  0  0  0  0 14 15  2]\n [ 0  0  0  0  0  0  0  0 14 15  2 16]\n [ 0  0  0  0  0  0  0 14 15  2 16 17]\n [ 0  0  0  0  0  0 14 15  2 16 17  1]\n [ 0  0  0  0  0 14 15  2 16 17  1  2]\n [ 0  0  0  0  0  0  0  0  0  0  0 19]\n [ 0  0  0  0  0  0  0  0  0  0 19 20]\n [ 0  0  0  0  0  0  0  0  0 19 20  3]\n [ 0  0  0  0  0  0  0  0 19 20  3 21]\n [ 0  0  0  0  0  0  0 19 20  3 21  4]\n [ 0  0  0  0  0  0 19 20  3 21  4  5]\n [ 0  0  0  0  0 19 20  3 21  4  5  6]\n [ 0  0  0  0 19 20  3 21  4  5  6 22]\n [ 0  0  0 19 20  3 21  4  5  6 22  4]\n [ 0  0 19 20  3 21  4  5  6 22  4  5]\n [ 0 19 20  3 21  4  5  6 22  4  5 23]\n [19 20  3 21  4  5  6 22  4  5 23  6]] (of type <class 'numpy.ndarray'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model (replace with your training data)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:120\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[1;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized data type: x=[[ 0  0  0  0  0  0  0  0  0  0  0  1]\n [ 0  0  0  0  0  0  0  0  0  0  1  7]\n [ 0  0  0  0  0  0  0  0  0  1  7  8]\n [ 0  0  0  0  0  0  0  0  1  7  8  9]\n [ 0  0  0  0  0  0  0  1  7  8  9 10]\n [ 0  0  0  0  0  0  1  7  8  9 10 11]\n [ 0  0  0  0  0  1  7  8  9 10 11  1]\n [ 0  0  0  0  1  7  8  9 10 11  1 12]\n [ 0  0  0  0  0  0  0  0  0  0  0 14]\n [ 0  0  0  0  0  0  0  0  0  0 14 15]\n [ 0  0  0  0  0  0  0  0  0 14 15  2]\n [ 0  0  0  0  0  0  0  0 14 15  2 16]\n [ 0  0  0  0  0  0  0 14 15  2 16 17]\n [ 0  0  0  0  0  0 14 15  2 16 17  1]\n [ 0  0  0  0  0 14 15  2 16 17  1  2]\n [ 0  0  0  0  0  0  0  0  0  0  0 19]\n [ 0  0  0  0  0  0  0  0  0  0 19 20]\n [ 0  0  0  0  0  0  0  0  0 19 20  3]\n [ 0  0  0  0  0  0  0  0 19 20  3 21]\n [ 0  0  0  0  0  0  0 19 20  3 21  4]\n [ 0  0  0  0  0  0 19 20  3 21  4  5]\n [ 0  0  0  0  0 19 20  3 21  4  5  6]\n [ 0  0  0  0 19 20  3 21  4  5  6 22]\n [ 0  0  0 19 20  3 21  4  5  6 22  4]\n [ 0  0 19 20  3 21  4  5  6 22  4  5]\n [ 0 19 20  3 21  4  5  6 22  4  5 23]\n [19 20  3 21  4  5  6 22  4  5 23  6]] (of type <class 'numpy.ndarray'>)"
     ]
    }
   ],
   "source": [
    "# Train the model (replace with your training data)\n",
    "model.fit(input_sequences, output_words, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next words based on user input\n",
    "user_input = \"The quick\"\n",
    "user_sequence = tokenizer.texts_to_sequences([user_input])[0]\n",
    "predicted_sequence = model.predict_classes(tf.expand_dims(user_sequence, axis=0), verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predicted sequence to words\n",
    "predicted_word = tokenizer.index_word[predicted_sequence[0]]\n",
    "print(f\"Predicted next word: {predicted_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

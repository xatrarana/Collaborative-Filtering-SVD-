{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as _pd\n",
    "import numpy as _np\n",
    "\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_authorData = _pd.read_csv('author_data.csv')\n",
    "_blogData = _pd.read_csv('blog_data.csv')\n",
    "_mediumBlogData = _pd.read_csv('medium_blog_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>blog_title</th>\n",
       "      <th>blog_content</th>\n",
       "      <th>blog_link</th>\n",
       "      <th>blog_img</th>\n",
       "      <th>topic</th>\n",
       "      <th>scrape_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Let’s Dominate The Launchpad Space Again</td>\n",
       "      <td>Hello, fam! If you’ve been with us since 2021,...</td>\n",
       "      <td>https://medium.com/@seedifyfund/lets-dominate-...</td>\n",
       "      <td>https://miro.medium.com/fit/c/140/140/1*nByLJr...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2023-02-27 07:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Let’s Dominate The Launchpad Space Again</td>\n",
       "      <td>Hello, fam! If you’ve been with us since 2021,...</td>\n",
       "      <td>https://medium.com/@seedifyfund/lets-dominate-...</td>\n",
       "      <td>https://miro.medium.com/fit/c/140/140/1*nByLJr...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2023-02-27 07:41:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Using ChatGPT for User Research</td>\n",
       "      <td>Applying AI to 4 common user research activiti...</td>\n",
       "      <td>https://medium.com/ux-planet/using-chatgpt-for...</td>\n",
       "      <td>https://miro.medium.com/fit/c/140/140/1*TZSGnN...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2023-02-27 07:41:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>The Automated Stable-Diffusion Checkpoint Merg...</td>\n",
       "      <td>Checkpoint merging is powerful. The power of c...</td>\n",
       "      <td>https://medium.com/@media_97267/the-automated-...</td>\n",
       "      <td>https://miro.medium.com/fit/c/140/140/1*x3N_Hj...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2023-02-27 07:41:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>The Art of Lazy Creativity: My Experience Co-W...</td>\n",
       "      <td>I was feeling particularly lazy one day and co...</td>\n",
       "      <td>https://medium.com/@digitalshedmedia/the-art-o...</td>\n",
       "      <td>https://miro.medium.com/fit/c/140/140/0*m2DdeT...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2023-02-27 07:41:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  author_id                                         blog_title  \\\n",
       "0        1          4           Let’s Dominate The Launchpad Space Again   \n",
       "1        3          4           Let’s Dominate The Launchpad Space Again   \n",
       "2        4          7                    Using ChatGPT for User Research   \n",
       "3        5          8  The Automated Stable-Diffusion Checkpoint Merg...   \n",
       "4        6          9  The Art of Lazy Creativity: My Experience Co-W...   \n",
       "\n",
       "                                        blog_content  \\\n",
       "0  Hello, fam! If you’ve been with us since 2021,...   \n",
       "1  Hello, fam! If you’ve been with us since 2021,...   \n",
       "2  Applying AI to 4 common user research activiti...   \n",
       "3  Checkpoint merging is powerful. The power of c...   \n",
       "4  I was feeling particularly lazy one day and co...   \n",
       "\n",
       "                                           blog_link  \\\n",
       "0  https://medium.com/@seedifyfund/lets-dominate-...   \n",
       "1  https://medium.com/@seedifyfund/lets-dominate-...   \n",
       "2  https://medium.com/ux-planet/using-chatgpt-for...   \n",
       "3  https://medium.com/@media_97267/the-automated-...   \n",
       "4  https://medium.com/@digitalshedmedia/the-art-o...   \n",
       "\n",
       "                                            blog_img topic  \\\n",
       "0  https://miro.medium.com/fit/c/140/140/1*nByLJr...    ai   \n",
       "1  https://miro.medium.com/fit/c/140/140/1*nByLJr...    ai   \n",
       "2  https://miro.medium.com/fit/c/140/140/1*TZSGnN...    ai   \n",
       "3  https://miro.medium.com/fit/c/140/140/1*x3N_Hj...    ai   \n",
       "4  https://miro.medium.com/fit/c/140/140/0*m2DdeT...    ai   \n",
       "\n",
       "           scrape_time  \n",
       "0  2023-02-27 07:37:48  \n",
       "1  2023-02-27 07:41:47  \n",
       "2  2023-02-27 07:41:47  \n",
       "3  2023-02-27 07:41:47  \n",
       "4  2023-02-27 07:41:47  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_authorData.head()\n",
    "_blogData.head()\n",
    "_mediumBlogData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200140, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_authorData.shape\n",
    "_blogData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  author_id topic\n",
       "0        1          4    ai\n",
       "1        3          4    ai\n",
       "2        4          7    ai\n",
       "3        5          8    ai\n",
       "4        6          9    ai"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removing the unwanted values\n",
    "_mediumBlogData.drop([\"blog_title\",\"blog_content\",\"blog_img\",\"blog_link\",\"scrape_time\"], axis=1, inplace=True)\n",
    "_mediumBlogData.shape\n",
    "\n",
    "_mediumBlogData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       blog_id  author_id            topic           author_name\n",
      "0            1          4               ai          Seedify Fund\n",
      "1            3          4               ai          Seedify Fund\n",
      "2          242          4             web3          Seedify Fund\n",
      "3          754          4       blockchain          Seedify Fund\n",
      "4            4          7               ai           Nick Babich\n",
      "...        ...        ...              ...                   ...\n",
      "10462    10485       6864  web-development  Fresh Frontend Links\n",
      "10463    10486       6865  web-development         Mukesh buwade\n",
      "10464    10487       6866  web-development            Osei Owusu\n",
      "10465    10489       6867  web-development        Yasas Sandeepa\n",
      "10466    10492       6868  web-development     Aphinya Dechalert\n",
      "\n",
      "[10467 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "_dataWithAuthor = _pd.merge(_mediumBlogData,_authorData, on='author_id')\n",
    "\n",
    "print(_dataWithAuthor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>author_name</th>\n",
       "      <th>userId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>624</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>2095</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>2103</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>2286</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  author_id topic   author_name  userId  ratings\n",
       "0        1          4    ai  Seedify Fund     624      2.0\n",
       "1        1          4    ai  Seedify Fund    1256      0.5\n",
       "2        1          4    ai  Seedify Fund    2095      3.5\n",
       "3        1          4    ai  Seedify Fund    2103      5.0\n",
       "4        1          4    ai  Seedify Fund    2286      2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_fullBlogData = _pd.merge(_dataWithAuthor,_blogData,on=\"blog_id\")\n",
    "_fullBlogData.shape\n",
    "_fullBlogData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>author_name</th>\n",
       "      <th>userId</th>\n",
       "      <th>ratings</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ai,Seedify Fund,2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>ai,Seedify Fund,0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>2095</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ai,Seedify Fund,3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>2103</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ai,Seedify Fund,5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ai</td>\n",
       "      <td>Seedify Fund</td>\n",
       "      <td>2286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ai,Seedify Fund,2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  author_id topic   author_name  userId  ratings  \\\n",
       "0        1          4    ai  Seedify Fund     624      2.0   \n",
       "1        1          4    ai  Seedify Fund    1256      0.5   \n",
       "2        1          4    ai  Seedify Fund    2095      3.5   \n",
       "3        1          4    ai  Seedify Fund    2103      5.0   \n",
       "4        1          4    ai  Seedify Fund    2286      2.0   \n",
       "\n",
       "              features  \n",
       "0  ai,Seedify Fund,2.0  \n",
       "1  ai,Seedify Fund,0.5  \n",
       "2  ai,Seedify Fund,3.5  \n",
       "3  ai,Seedify Fund,5.0  \n",
       "4  ai,Seedify Fund,2.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_fullBlogData[\"features\"] = _fullBlogData[\"topic\"] + ',' + _fullBlogData[\"author_name\"] + ',' + _fullBlogData[\"ratings\"].astype(str)\n",
    "_fullBlogData.shape\n",
    "_fullBlogData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userId  num_ratings\n",
      "0         10           19\n",
      "1         11           16\n",
      "2         12           71\n",
      "3         13           51\n",
      "4         14          170\n",
      "...      ...          ...\n",
      "4996    5006            9\n",
      "4997    5007           49\n",
      "4998    5008           31\n",
      "4999    5009          107\n",
      "5000    5010           40\n",
      "\n",
      "[5001 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Number of ratings per user\n",
    "ratings_per_user = _fullBlogData.groupby('userId').size().reset_index(name='num_ratings')\n",
    "\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  blog_id  ratings\n",
      "0           10      137        1\n",
      "1           10      142        1\n",
      "2           10      145        1\n",
      "3           10      152        1\n",
      "4           10      158        1\n",
      "...        ...      ...      ...\n",
      "200123    5010     9735        1\n",
      "200124    5010     9736        1\n",
      "200125    5010     9737        1\n",
      "200126    5010     9741        1\n",
      "200127    5010     9750        1\n",
      "\n",
      "[200128 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Number of ratings blog per user\n",
    "rating_counts = _fullBlogData.groupby(['userId', 'blog_id']).size().reset_index(name='ratings')\n",
    "\n",
    "print(rating_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ratings to NumPy array\n",
    "ratings = _fullBlogData['ratings'].values\n",
    "\n",
    "# Convert userIds to NumPy array\n",
    "user_ids = _fullBlogData['userId'].values\n",
    "\n",
    "# Calculate number of ratings per user\n",
    "unique_users, ratings_count = _np.unique(user_ids, return_counts=True)\n",
    "\n",
    "# Calculate average number of ratings per user\n",
    "average_ratings_per_user = _np.mean(ratings_count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_scale = (0.5, 5.0)\n",
    "reader = Reader(rating_scale=rating_scale)\n",
    "data = Dataset.load_from_df(_fullBlogData[['userId', 'blog_id', 'ratings']], reader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2827f5ecb30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the algorithm on the training set\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Recommend items for a specific user (userId = 1)\n",
    "userId = 12\n",
    "items_to_predict = _fullBlogData['blog_id'].unique()\n",
    "predictions = [algo.predict(userId, blog_id) for blog_id in items_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Blog ID 8791 (Estimated rating: 4.73903107414081)\n",
      "Rank 2: Blog ID 275 (Estimated rating: 4.725343853797849)\n",
      "Rank 3: Blog ID 3965 (Estimated rating: 4.660631083675385)\n",
      "Rank 4: Blog ID 6740 (Estimated rating: 4.626595907630862)\n",
      "Rank 5: Blog ID 8569 (Estimated rating: 4.570424582640152)\n",
      "Rank 6: Blog ID 5713 (Estimated rating: 4.534783741477136)\n",
      "Rank 7: Blog ID 8214 (Estimated rating: 4.5206987528346705)\n",
      "Rank 8: Blog ID 2807 (Estimated rating: 4.478466172141897)\n",
      "Rank 9: Blog ID 9560 (Estimated rating: 4.453017522800084)\n",
      "Rank 10: Blog ID 6550 (Estimated rating: 4.4354961518954426)\n"
     ]
    }
   ],
   "source": [
    "#Sort and present recommendations\n",
    "\n",
    "# Sort predictions by estimated rating in descending order\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Get top-N recommendations\n",
    "top_n = 10\n",
    "top_predictions = predictions[:top_n]\n",
    "\n",
    "# Display recommendations\n",
    "for i, prediction in enumerate(top_predictions, 1):\n",
    "    print(f\"Rank {i}: Blog ID {prediction.iid} (Estimated rating: {prediction.est})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Recommendations for User 12 based on topic 'ai':\n",
      "Rank 1: Blog ID 3145 (Topic: ai, Author: Christie C., Estimated Rating: 4.189758736029309)\n",
      "Rank 2: Blog ID 1378 (Topic: ai, Author: steven arellano, Estimated Rating: 4.150173328135927)\n",
      "Rank 3: Blog ID 18 (Topic: ai, Author: Matt Ryan Allen, Estimated Rating: 4.117055379996544)\n",
      "Rank 4: Blog ID 3160 (Topic: ai, Author: Swapna M, Estimated Rating: 4.036207681033946)\n",
      "Rank 5: Blog ID 3221 (Topic: ai, Author: Melissa Lim, Estimated Rating: 4.025205024964296)\n"
     ]
    }
   ],
   "source": [
    "# recommend based on the topic\n",
    "\n",
    "selected_topic = 'ai'\n",
    "\n",
    "# Step 2: Generate predictions for items related to the selected topic\n",
    "topic_related_items = _fullBlogData[_fullBlogData['topic'] == selected_topic]['blog_id'].unique()\n",
    "\n",
    "predictions = []\n",
    "for blog_id in topic_related_items:\n",
    "    prediction = algo.predict(userId, blog_id)\n",
    "    predictions.append((blog_id, prediction.est))\n",
    "\n",
    "# Step 3: Sort predictions based on estimated ratings (est) in descending order\n",
    "predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top recommended items\n",
    "\n",
    "top_n = 5 \n",
    "\n",
    "print(f\"Top {top_n} Recommendations for User {userId} based on topic '{selected_topic}':\")\n",
    "\n",
    "for i, (blog_id, estimated_rating) in enumerate(predictions[:top_n], 1):\n",
    "    blog_info = _fullBlogData[_fullBlogData['blog_id'] == blog_id].iloc[0]\n",
    "    print(f\"Rank {i}: Blog ID {blog_id} (Topic: {blog_info['topic']}, Author: {blog_info['author_name']}, Estimated Rating: {estimated_rating})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating for User 3 on Blog 123: 2.920325435150373\n"
     ]
    }
   ],
   "source": [
    "# Example: Predicting user rating for a specific blog\n",
    "\n",
    "userId3 = 3 \n",
    "blog_id = 123  \n",
    "\n",
    "prediction = algo.predict(userId3, blog_id)\n",
    "\n",
    "# Display prediction result\n",
    "print(f\"Predicted Rating for User {userId3} on Blog {blog_id}: {prediction.est}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Unrated Blogs Predicted to be Rated by User 12:\n",
      "Rank 1: Blog ID 275 (Topic: cybersecurity, Author: Ama Victor, Estimated Rating: 4.725343853797849)\n",
      "Rank 2: Blog ID 3965 (Topic: information-security, Author: Trishank Karthik Kuppusamy, Estimated Rating: 4.660631083675385)\n",
      "Rank 3: Blog ID 6740 (Topic: data-analysis, Author: Juan De Dios Santos, Estimated Rating: 4.626595907630862)\n",
      "Rank 4: Blog ID 8569 (Topic: app-development, Author: Prakriti Jain, Estimated Rating: 4.570424582640152)\n",
      "Rank 5: Blog ID 5713 (Topic: deep-learning, Author: Vinicius Queiroz, Estimated Rating: 4.534783741477136)\n"
     ]
    }
   ],
   "source": [
    "# Example: Showing unrated blogs predicted to be rated by a user\n",
    "\n",
    "\n",
    "# Get list of all blog IDs\n",
    "all_blog_ids = _fullBlogData['blog_id'].unique()\n",
    "\n",
    "# Get list of blog IDs rated by the user\n",
    "rated_blog_ids = _fullBlogData[_fullBlogData['userId'] == userId]['blog_id'].unique()\n",
    "\n",
    "# Filter out unrated blog IDs\n",
    "unrated_blog_ids = list(set(all_blog_ids) - set(rated_blog_ids))\n",
    "\n",
    "# Generate predictions for unrated blogs\n",
    "predictions = []\n",
    "for blog_id in unrated_blog_ids:\n",
    "    prediction = algo.predict(userId, blog_id)\n",
    "    predictions.append((blog_id, prediction.est))\n",
    "\n",
    "\n",
    "predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top unrated blogs predicted to be rated by the user\n",
    "top_n = 5  \n",
    "print(f\"Top {top_n} Unrated Blogs Predicted to be Rated by User {userId}:\")\n",
    "for i, (blog_id, estimated_rating) in enumerate(predictions[:top_n], 1):\n",
    "    blog_info = _fullBlogData[_fullBlogData['blog_id'] == blog_id].iloc[0] \n",
    "    print(f\"Rank {i}: Blog ID {blog_id} (Topic: {blog_info['topic']}, Author: {blog_info['author_name']}, Estimated Rating: {estimated_rating})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rated_blog_id \u001b[38;5;129;01min\u001b[39;00m rated_blog_ids:\n\u001b[0;32m     35\u001b[0m     rated_blog_info \u001b[38;5;241m=\u001b[39m blog_features[blog_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblog_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m rated_blog_id]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 36\u001b[0m     similarity_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblog_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrated_blog_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[41], line 25\u001b[0m, in \u001b[0;36mcalculate_similarity\u001b[1;34m(blog1, blog2)\u001b[0m\n\u001b[0;32m     23\u001b[0m features1 \u001b[38;5;241m=\u001b[39m blog1[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_name\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m features2 \u001b[38;5;241m=\u001b[39m blog2[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_name\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures2\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1668\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1668\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1670\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:174\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    164\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         X,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    184\u001b[0m         Y,\n\u001b[0;32m    185\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1007\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1007\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1011\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chhat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:746\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    744\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ai'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example features (replace with actual features extracted from your data)\n",
    "blog_features = _fullBlogData[['blog_id', 'topic', 'author_name']]\n",
    "\n",
    "# Assume userId is defined as in the previous example\n",
    "# userId = 1\n",
    "\n",
    "# Get blog IDs rated by the user\n",
    "rated_blog_ids = _fullBlogData[_fullBlogData['userId'] == userId]['blog_id'].unique()\n",
    "\n",
    "# Generate predictions for rated blogs using collaborative filtering\n",
    "predictions_collab = []\n",
    "for blog_id in rated_blog_ids:\n",
    "    prediction = algo.predict(userId, blog_id)\n",
    "    predictions_collab.append((blog_id, prediction.est))\n",
    "\n",
    "# Sort collaborative filtering predictions by estimated rating (highest to lowest)\n",
    "predictions_collab.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Content-Based Filtering: Calculate similarity based on 'topic' and 'author_name'\n",
    "def calculate_similarity(blog1, blog2):\n",
    "    features1 = blog1[['topic', 'author_name']].values.reshape(1, -1)\n",
    "    features2 = blog2[['topic', 'author_name']].values.reshape(1, -1)\n",
    "    return cosine_similarity(features1, features2)[0][0]\n",
    "\n",
    "# Generate similarities for all blogs with respect to rated blogs\n",
    "similarities = []\n",
    "for blog_id in blog_features['blog_id'].unique():\n",
    "    if blog_id not in rated_blog_ids:\n",
    "        blog_info = blog_features[blog_features['blog_id'] == blog_id].iloc[0]\n",
    "        similarity_sum = 0\n",
    "        count = 0\n",
    "        for rated_blog_id in rated_blog_ids:\n",
    "            rated_blog_info = blog_features[blog_features['blog_id'] == rated_blog_id].iloc[0]\n",
    "            similarity_sum += calculate_similarity(blog_info, rated_blog_info)\n",
    "            count += 1\n",
    "        if count > 0:\n",
    "            average_similarity = similarity_sum / count\n",
    "            similarities.append((blog_id, average_similarity))\n",
    "\n",
    "# Sort blogs by content-based similarity (highest to lowest)\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top recommended blogs combining both approaches\n",
    "top_n = 5\n",
    "print(f\"Top {top_n} Combined Recommendations Based on Ratings and Content Similarity for User {userId}:\")\n",
    "for i, (blog_id, similarity) in enumerate(similarities[:top_n], 1):\n",
    "    blog_info = _fullBlogData[_fullBlogData['blog_id'] == blog_id].iloc[0]\n",
    "    print(f\"Rank {i}: Blog ID {blog_id} (Topic: {blog_info['topic']}, Author: {blog_info['author_name']}, Similarity: {similarity})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
